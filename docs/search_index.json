[["index.html", "Elementos de la estadística estadística descriptiva y probabilidades Resumen", " Elementos de la estadística estadística descriptiva y probabilidades Ricardo Michel MALLQUI BAÑOS 2021-10-06 Resumen La estadística es la ciencia que manipula datos las analiza e interpreta para poder sacar concluciones razonables de ciertos fenomenos naturales. Esta ciencia puede ser dividido en dos: estadística descirptiva y estadística inferencial. En la estadística descriptiva se procesan datos de una manera teórica y utilitaria. Estos métodos consisten en la recolección, organización, resumen, descripcion y presenatacion de la información. Si la poblacion está disponible entonces la estadística descriptiva es suficiente para describir ciertos fenomenos. No obstante generalmente no se dispone de toda la población si no de una muestra de ella, es en este caso que se requieren usar técnicas más sofisticadas para tomar decisiones y generalizaciones acerca de la poblacion, desde una pequeña muestra de información. Es cuando entra en el juego la estadística inferencial. La base teórica de la estadística son las matemáticas Este libro se compone de dos partes, la primera parte trata sobre la estadística descirptiva y la segunda estadística inferencial. Cada una de ellas divididas en capítulos. "],["prerrequisitos.html", "Capítulo 1 Prerrequisitos", " Capítulo 1 Prerrequisitos WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW "],["medidas-de-asimetria.html", "Capítulo 2 Medidas de asimetria 2.1 wwwwww", " Capítulo 2 Medidas de asimetria 2.0.1 Datos no agrupados Si \\[P_k=\\frac{k(n+1)}{100}; k=1, 2, \\ldots, 99\\] es entero entonces el cuartil es el dato de la posicion \\(P_k=x_\\frac{k(n+1)}{100}\\) Si \\[P_k=\\frac{k(n+1)}{100}\\] no es entero entonces el cuartil es la interpolacion lineal de de los dos valores entre las cuales se encuentra \\(Q_k=\\frac{k(n+1)}{100}\\) Ejemplo 1, 2, 5, 1 ,5, 6, 7, 8, 9, 3, 4, 5, 2, 6, 2, 5, 6, 7 Al ordenar de manera creciente 1, 2, 5, 1 ,5, 6, 7, 8, 9, 3, 4, 5, 2, 6, 2, 5, 6, 7 y \\[P_k=\\frac{k(18+1)}{100}\\] 2.0.2 Datos agrupados \\[P_k=L_i+ A\\left(\\frac{\\frac{kn}{100}-F_{i-1}}{F_i-F_{i-1}}\\right)=\\int_1^3f(x)\\] Clase \\(Y_i\\) \\(f_i\\) \\(F_i\\) \\([5,10)\\) 7.5 1 1 \\([10,15)\\) 12.5 2 3 \\([15,20)\\) 17.5 5 \\([20,25)\\) 22.5 7 \\([25,30]\\) 10 \\([30,35]\\) 6 \\([35,40]\\) 5 \\([40,45]\\) 3 \\(\\sum\\) 2 2.0.3 Datos no agrupados Si \\[P_k=\\frac{k(n+1)}{100}; k=1, 2, \\ldots, 99\\] es entero entonces el cuartil es el dato de la posicion \\(P_k=x_\\frac{k(n+1)}{100}\\) Si \\[P_k=\\frac{k(n+1)}{100}\\] no es entero entonces el cuartil es la interpolacion lineal de de los dos valores entre las cuales se encuentra \\(Q_k=\\frac{k(n+1)}{100}\\) Ejemplo 1, 2, 5, 1 ,5, 6, 7, 8, 9, 3, 4, 5, 2, 6, 2, 5, 6, 7 Al ordenar de manera creciente 1, 2, 5, 1 ,5, 6, 7, 8, 9, 3, 4, 5, 2, 6, 2, 5, 6, 7 y \\[P_k=\\frac{k(18+1)}{100}\\] 2.0.4 Datos agrupados \\[P_k=L_i+ A\\left(\\frac{\\frac{kn}{100}-F_{i-1}}{F_i-F_{i-1}}\\right)=\\int_1^3f(x)\\] Clase \\(Y_i\\) \\(f_i\\) \\(F_i\\) \\([5,10)\\) 7.5 1 1 \\([10,15)\\) 12.5 2 3 \\([15,20)\\) 17.5 5 \\([20,25)\\) 22.5 7 \\([25,30]\\) 10 \\([30,35]\\) 6 \\([35,40]\\) 5 \\([40,45]\\) 3 \\(\\sum\\) 2 2.1 wwwwww 2.1.1 Datos no agrupados Si \\[P_k=\\frac{k(n+1)}{100}; k=1, 2, \\ldots, 99\\] es entero entonces el cuartil es el dato de la posicion \\(P_k=x_\\frac{k(n+1)}{100}\\) Si \\[P_k=\\frac{k(n+1)}{100}\\] no es entero entonces el cuartil es la interpolacion lineal de de los dos valores entre las cuales se encuentra \\(Q_k=\\frac{k(n+1)}{100}\\) Ejemplo 1, 2, 5, 1 ,5, 6, 7, 8, 9, 3, 4, 5, 2, 6, 2, 5, 6, 7 Al ordenar de manera creciente 1, 2, 5, 1 ,5, 6, 7, 8, 9, 3, 4, 5, 2, 6, 2, 5, 6, 7 y \\[P_k=\\frac{k(18+1)}{100}\\] 2.1.2 Datos agrupados \\[P_k=L_i+ A\\left(\\frac{\\frac{kn}{100}-F_{i-1}}{F_i-F_{i-1}}\\right)=\\int_1^3f(x)=\\int_1^3\\] Clase \\(Y_i\\) \\(f_i\\) \\(F_i\\) \\([5,10)\\) 7.5 1 1 \\([10,15)\\) 12.5 2 3 \\([15,20)\\) 17.5 5 \\([20,25)\\) 22.5 7 \\([25,30]\\) 10 \\([30,35]\\) 6 \\([35,40]\\) 5 \\([40,45]\\) 3 \\(\\sum\\) 2 "],["medidas-de-curtosis-o-apuntamiento.html", "Capítulo 3 Medidas de curtosis o apuntamiento", " Capítulo 3 Medidas de curtosis o apuntamiento En estadística, usamos la medida de curtosis para describir la cola de la distribución, ya que describe la forma de la misma. También es una medida del pico de la distribución. Una distribución de curtosis alta tiene un pico más agudo y colas más largas y gruesas, mientras que una distribución de curtosis baja tiene un maní más redondeado y colas más cortas y delgadas. Datos no agrupados \\[k= \\frac{\\sum_{i=1}^{n}\\left( x_i-\\overline{x} \\right)^4 }{n} \\] Datos agrupados \\[ K=\\frac{\\sum_{i=1}^{n}\\left( x_i-\\overline{x} \\right)^4 }{n} \\] Mesocurtico : esta es la distribución normal Leptocurtica : esta distribución tiene colas más gruesas y un pico más afilado. La curtosis es positiva con un valor superior a 3 Platicurtica : La distribución tiene un pico más bajo y más ancho y colas más delgadas. La curtosis es negativa con un valor superior a 3 https://link "],["medidas-de-asimetría.html", "Capítulo 4 Medidas de asimetría", " Capítulo 4 Medidas de asimetría Podemos decir que la asimetría indica cuánto se desvía nuestra distribución subyacente de la distribución normal, ya que la distribución normal tiene asimetría 0. Generalmente, tenemos tres tipos de asimetría. Simétrico : cuando la asimetría es cercana a 0 y la media es casi la misma que la mediana Desviación negativa : cuando la cola izquierda del histograma de la distribución es más larga y la mayoría de las observaciones se concentran en la cola derecha. En este caso, también podemos utilizar el término sesgado a la izquierda o cola izquierda. y la mediana es mayor que la media. Desviación positiva : cuando la cola derecha del histograma de la distribución es más larga y la mayoría de las observaciones se concentran en la cola izquierda. En este caso, también podemos usar el término sesgado a la derecha o cola derecha. y la mediana es menor que la media. alt data = c(88, 95, 92, 97, 96, 97, 94, 86, 91, 95, 97, 88, 85, 76, 68) hist(data, col=&#39;steelblue&#39;) dens &lt;- density(data) plot(dens, frame = FALSE, col = &quot;steelblue&quot;, main = &quot;Density plot of mpg&quot;) polygon(dens, col = &quot;steelblue&quot;) ggplot(data=iris, aes(Petal.Length,fill=Species)) + geom_density(alpha=0.7) # dibujamos el diagrama de densidad "],["experimento-aleatorio.html", "Capítulo 5 Experimento aleatorio", " Capítulo 5 Experimento aleatorio Definición 5.1 (Experimento aleatorio) En experiento aleatorio es un fenomeno que genera un evento "],["álgebra-de-eventos.html", "Capítulo 6 Álgebra de eventos", " Capítulo 6 Álgebra de eventos Sean \\(A\\), \\(B\\) y \\(C\\) eventos entonces 1. e 2. wwwwwwwwwwwwwwwwwwwwwwwwwwwwww \\[ \\int_{1}^{2}=\\sum_{2}^{2}x_1 \\] "],["técnicas-de-conteo.html", "Capítulo 7 Técnicas de conteo", " Capítulo 7 Técnicas de conteo \\(P_n^m\\) \\(C_n^m\\) \\[\\binom{m}{n}=\\frac{m}{n!(n-m)}\\] "],["definición-de-probabilidad.html", "Capítulo 8 Definición de probabilidad", " Capítulo 8 Definición de probabilidad "],["probabilidad-condicional.html", "Capítulo 9 Probabilidad condicional", " Capítulo 9 Probabilidad condicional \\[P(A|B)= \\frac{P(B\\cap A)}{P(B)}\\] "],["teorema-de-bayes.html", "Capítulo 10 Teorema de Bayes", " Capítulo 10 Teorema de Bayes Teorema 10.1 (Teorema de Bayes) Sea \\(\\{A_{1},A_{2},...,A_{i},...,A_{n}\\}\\) un conjunto de sucesos mutuamente excluyentes y exhaustivos, y tales que la probabilidad de cada uno de ellos es distinta de cero (0). Sea \\(B\\) un suceso cualquiera del que se conocen las probabilidades condicionales \\(P(B|A_i )\\). Entonces, la probabilidad \\(P(A_i|B)\\) viene dada por la expresión: \\[P(A_i|B)=\\frac{P(B|A_i)P(A_i)}{P(B)}\\] donde: \\(P(A_i)\\) son las probabilidades a priori, \\(P(B|A_i)\\) es la probabilidad de B en la hipótesis \\(A_i\\), \\(P(A_i|B)\\) son las probabilidades a posteriori. "],["eventos-independientes-y-secuencias-de-experimentos.html", "Capítulo 11 Eventos independientes y secuencias de experimentos", " Capítulo 11 Eventos independientes y secuencias de experimentos "],["probabilidad-en-espacio.html", "Capítulo 12 Probabilidad en espacio", " Capítulo 12 Probabilidad en espacio "],["variables-aleatorias.html", "Capítulo 13 Variables aleatorias 13.1 Clases de variables aleatorias 13.2 Función de probabilidad de una variable aleatoria 13.3 Función de distribución de una variable aleatoria", " Capítulo 13 Variables aleatorias Definición 13.1 (Variable aleatoria) Sea \\(\\Omega\\) un espacio muestral asociado a una experimento aleatorio \\(\\epsilon\\) y \\(\\omega\\in\\Omega\\), entonces se genera la función variable aleatoria \\[\\begin{align*} X:\\Omega&amp;\\longrightarrow \\mathbb{R}\\\\ \\omega&amp;\\longmapsto X(\\omega) \\end{align*}\\] \\(R_{X}=\\{x\\in \\mathbb {R} /\\ \\exists \\,\\omega \\in \\Omega :X(\\omega )=x\\}\\) es decir a cada elemento de \\(\\Omega\\) se le asocia un número real \\(\\mathbb{R}\\), además la probabilidad de \\(x\\in \\mathbb{R}\\) es \\(P[x]= \\sum^{n}_{i=1}P\\left[\\omega_i\\right]\\) donde \\(\\omega_i\\in X^{-1}(x)\\). La definición indica por otro lado que un espacio muestral \\(\\Omega\\) puede genera diferentes variables aleatorias. Ejemplo 13.1 El espacio muestral de lanzar una monedas tres veces es \\[\\omega= \\left\\{ccc,ccs,csc,scc,css,scs,ssc,sss\\right\\}\\] además sea \\(n_c\\) es número de caras y \\(n_s\\) el número de sellos, es posibles generar dos o mas variables aleatorias por ejemplo: \\(X(\\omega)=n_c\\) entonces el rango de \\(X\\) es \\(R_X \\left\\{3,2,1,0\\right\\}\\) pues \\[\\begin{align*} 3&amp;=X(ccc)&amp;\\\\ 2&amp;=X(ccs)=X(csc)=X(scc)&amp;\\\\ 1&amp;=X(css)=X(scs)=X(ssc)&amp;\\\\ 0&amp;=X(sss)&amp; \\end{align*}\\] \\(X(\\omega)=n_c-n_s\\) entonces las imagenes de \\(X\\) son \\(R_X= \\left\\{3,1,-1,-3\\right\\}\\) en efecto \\[\\begin{align*} 3&amp;=X(ccc)&amp;\\\\ 1&amp;=X(ccs)=X(csc)=X(scc)&amp;\\\\ -1&amp;=X(css)=X(scs)=X(ssc)&amp;\\\\ -3&amp;=X(sss).&amp; \\end{align*}\\] Estos subconjuntos de \\(\\mathbb{R}\\) también son espacios muestrales pues el conjunto de elementos de \\(\\Omega\\) con imagen dentro de estos valores reales \\(x\\) en \\(\\mathbb{R}\\) es un elemento de \\(2^{\\Omega}\\) es decir un evento por lo tanto tiene una determinada probabilidad \\(P[x]\\), en el primer caso \\(X(\\omega)=n_c\\) tienen probabilidades \\[\\begin{align*} P(3)&amp;=P[ccc]= \\frac{1}{8}\\\\ P(2)&amp;=P[ccs]=P[csc]=P[scc]=\\frac{3}{8}\\\\ P(1)&amp;=P[css]=P[scs]=P[ssc]=\\frac{3}{8}\\\\ P(0)&amp;=P[sss]=\\frac{1}{8} \\end{align*}\\] que es lo mismo para el segundo caso \\(X(\\omega)=n_c-n_s\\). Definición 13.2 (Eventos equivalentes) Sea \\(\\Omega\\) un espacio muestral asociado a una experimento aleatorio \\(\\epsilon\\) y \\(X\\) una variable aleatoria con rango \\(R_X\\) definida sobre \\(\\Omega\\). Dos eventos \\(W\\in\\Omega\\) y \\(E_X\\in R_X\\) son eventos equivalentes si existe la relación \\[W= \\left\\{\\omega\\in\\Omega/X(\\omega)=E_X\\right\\}\\] es decir \\(E_X\\) consta de todos los elementos en \\(\\Omega\\) para los cuales \\(X(\\omega)\\in W\\) 13.1 Clases de variables aleatorias 13.1.1 Variable aleatoria discreta Cuando el rango de la variable aleatoria \\(X\\), \\(R_X\\) es finito o infinito contable (no necesarimente enteros) \\(R_X= \\left\\{x_1,x_2,\\ldots,x_n\\ldots\\right\\}\\) 13.1.2 Variable aleatoria continua \\(R_X\\) abarca cualquier intervalo en la recta numerica 13.1.3 Variable aleatoria mixta Discreta y continua 13.2 Función de probabilidad de una variable aleatoria 13.2.1 Función de probabilidad de una variable aleatorias discreta Definición 13.3 (Función o ley de probabilidad) Sea \\(X\\) una variable aleatoria con rango \\(R_X\\). Una función definida por \\[p(x)=P[X=x]= \\sum^{}_{ \\left\\{\\omega \\in \\Omega:X(\\omega)=x\\right\\}}P\\left[\\left\\{\\omega\\right\\}\\right]\\] \\(p(x)&gt;0\\), \\(x\\in R_X\\) \\(\\sum_{x\\in R_X}p(x)=P[X=x]=1\\) El conjunto de pares ordenados \\(\\left(x,p(x)\\right)\\), \\(x\\in R_X\\) recibe el nombre de distribución de probabildiad de \\(X\\) Ejemplo 13.2 La variable aleatoria discreta \\[p_X(x)=p(1-p)^{x-1}, \\text{ $x\\in \\mathbb{Z}^+$ y $p\\in[0,1]$}\\] en efecto \\[p(1-p)^{i-1}&gt;0, \\text{ $\\forall x\\in \\mathbb{Z}^+$}\\] además \\[ \\sum^{\\infty}_{i=1}p(1-p)^{i-1}=p \\lim_{n\\to\\infty}\\frac{1-(1-p)^{n+1}}{1-(1-p)}=1\\] Ejemplo 13.3 La variable aleatoria discreta \\[p_X(x)=p(1-p), \\text{ $x\\in \\mathbb{Z}^+$ y $p\\in[0,1]$}\\] en efecto \\[p(1-p)^{i-1}&gt;0, \\text{ $\\forall x\\in \\mathbb{Z}^+$}\\] además \\[ \\sum^{\\infty}_{i=1}p(1-p)^{i-1}=p \\lim_{n\\to\\infty}\\frac{1-(1-p)^{n+1}}{1-(1-p)}=1\\] Ejemplo 13.4 La variable aleatoria discreta \\[p_X(x)=(1-p)^{x-1}, \\text{ $x\\in \\mathbb{Z}^+$ y $p\\in[0,1]$}\\] en efecto \\[p(1-p)^{i-1}&gt;0, \\text{ $\\forall x\\in \\mathbb{Z}^+$}\\] además \\[ \\sum^{\\infty}_{i=1}p(1-p)^{i-1}=p \\lim_{n\\to\\infty}\\frac{1-(1-p)^{n+1}}{1-(1-p)}=1\\] 13.2.2 Función de probabilidad de una variable aleatoria continua Definición 13.4 (Función de densidad de probabilidad) Sea \\(X\\) una variable aleatoria con rango \\(R_X\\). La función \\(f(x)\\) definida sobre \\(R_X\\) \\(f(x)&gt;0\\), \\(x\\in R_X\\) o \\(f(x)&gt;0\\), \\(x\\in \\mathbb{R}\\) \\(\\int_{R_X}f(x)dx=1\\) o \\(\\int_{-\\infty}^{\\infty}f(x)dx=1\\) Ejemplo 13.5 For a circle with the radius r x, its area is r pi * x^2. Sea la función \\[\\frac{1}{x^2} =1 \\] \\[\\frac{\\sin x}{x^3} =0.3794281 \\] \\[\\Phi_{\\mu ,\\sigma ^{2}}(x)=\\frac {1}{\\sigma {\\sqrt {2\\pi }}}e^{-{\\frac {(u-\\mu )^{2}}{2\\sigma ^{2}}}}du \\] Ejemplo 13.6 Sea \\(f(x)= \\frac{\\alpha}{\\rho}\\) es una funcion de densidad pues \\[f(x)&gt;0,~ x\\in R_X\\] además \\[\\int_{R_X}f(x)dx=1\\] Ejemplo 13.7 Sea \\(f(x)= \\frac{\\sigma}{\\rho}\\) es una funcion de densidad pues \\[f(x)&gt;0,~ x\\in R_X\\] además \\[\\int_{R_X}f(x)dx=1\\] 13.3 Función de distribución de una variable aleatoria 13.3.1 Función de distribución de una variable aleatoria discreta Definición 13.5 (Función de distribución) Sea \\(X\\) una variable aleatoria con rango \\[R_X= \\left\\{x_1,x_2,\\ldots x_n,\\ldots\\right\\}.\\] Con función de probabilidad \\(p(x_i)=P[X=x_i]\\), sea \\(x\\) cualquier número, real la función definida por \\[F(x)=P[X\\leq x]= \\sum^{}_{x_i\\leq x}p(x_i)= \\sum^{}_{x_i\\leq x}P[X= x_i] \\] recie el nombre de función de distribución de \\(X\\). Cuyas propiedades son: \\(0\\leq F_X(x)\\leq 1\\) \\(F_X(-\\infty)=0\\) \\(F_X(\\infty)=1\\) \\(P(X&lt;x)=F_X(x^-)\\) \\(P(a\\leq X\\leq b)=F_X(b)-F_X(a^-)\\) Ejemplo 13.8 wwwwwww Ejemplo 13.9 wwwwwww Ejemplo 13.10 wwwwwww 13.3.2 Función de distribución de una variable aleatoria continua Definición 13.6 (Función de distribución) Sea \\(X\\) una variable aleatoria con función de densidad \\(f(x)\\). La función \\[F_X(x)=F(x)=P[X\\leq x]=\\int_{-\\infty}^{x}f(t)dt, \\text{ $\\forall x\\in R_X$}\\] Cuyas propiedades son: \\(0\\leq F(x)\\leq 1\\) \\(F(-\\infty)=0\\) \\(F(\\infty)=1\\) Ejemplo 13.11 wwwwwww Ejemplo 13.12 wwwwwww Ejemplo 13.13 wwwwwww "],["parámetros-de-una-variable-aleatoria.html", "Capítulo 14 Parámetros de una variable aleatoria 14.1 Esperanza matemática 14.2 Medidas de variación 14.3 Medidas de posición 14.4 Medidas de curtosis", " Capítulo 14 Parámetros de una variable aleatoria 14.1 Esperanza matemática Definición 14.1 (Esperanza matemática de una variable aleatoria discreta) \\[\\mathbb{E}[X]=\\sum _{i=1}^{n}x_{i}p(x_{i})\\] Definición 14.2 (Esperanza matemática de una variable aleatoria continua) \\[\\mathbb{E}[X]=\\int_{-\\infty }^{\\infty}xf(x)dx \\text{ equivalentemente }\\mathbb {E}[X]=\\int_{\\Omega }X\\,{\\text{d}}P\\] el valor esperado a veces se representa por \\(\\mu =\\mathbb {E} [X]\\) que es el promedio o la media poblacional. 14.2 Medidas de variación La varianza es una medida de dispersión de una variable aleatoria \\(X\\) respecto a su esperanza \\(\\mathbb {E} [X]\\). Se define como la esperanza de la transformación \\[\\rho=\\text{Var}(X)=\\left(X-\\mathbb {E} [X]\\right)^{2}\\] \\[\\sigma =\\sqrt{\\text{Var}(X)}\\] o bien \\[\\sigma^{2}=\\text{Var}(X)\\] Definición 14.3 (Varianza de una variable aleatoria discreta) Sea Definición 14.4 (Varianza matemática de una variable aleatoria continua) Sea 14.3 Medidas de posición Definición 14.5 (Cuantiles de una variable aleatoria discreta) Sea Definición 14.6 (Cuantiles matemática de una variable aleatoria continua) Sea 14.4 Medidas de curtosis Definición 14.7 (Curtosis de una variable aleatoria discreta) Sea Definición 14.8 (Curtosis de una variable aleatoria continua) Sea momento de orden superior \\[{\\displaystyle M_{X}^{(n)}=\\mathbb {E} [X^{n}]=\\int _{\\mathbb {R} }x^{n}f_{X}(x)\\ {\\text{d}}x}\\] "],["variables-aleatorias-bidimensionales.html", "Capítulo 15 Variables aleatorias bidimensionales 15.1 Distribución bidimensional discreta 15.2 Distribución bidimensional continua", " Capítulo 15 Variables aleatorias bidimensionales Definición 15.1 (Variable aleatoria bidmensional discreta) \\[F(x,y)=P[X\\leq x,Y\\leq y]= \\sum^{x}_{u=-\\infty}\\sum^{y}_{v=-\\infty}=p(u,v)\\] Ejemplo 15.1 Definición 15.2 (Variable aleatoria bidmensional contínua) \\[F(x,y)=P[X\\leq x,Y\\leq y]= \\sum^{x}_{u=-\\infty}\\sum^{y}_{v=-\\infty}=p(u,v)\\] Ejemplo 15.2 15.1 Distribución bidimensional discreta Definición 15.3 (Función de probabilidad conjunta) Sea \\((X,Y)\\) una variable bidimensinal discreta con rango \\(R_{X\\times Y}\\). A cada posible resultado le asociamos un numero \\[p(x,y)=P[X=x, Y=y]\\] que cumple la siguientes condiciones \\(1&gt;p(x,y)&gt;0\\), \\((x,y)\\in R_{X\\times Y}\\in\\) \\(\\sum^{}_{x\\in R_X} \\sum^{}_{y\\in R_Y}p(x,y)=1\\) Alos pares ordenados \\(\\left((x,y),p(x,y)\\right)\\) se le llama distribución de probabilidad conjunta Definición 15.4 (Función de distribución acumulada) \\[F(x,y)=P[X\\leq x,Y\\leq y]= \\sum^{x}_{u=-\\infty}\\sum^{y}_{v=-\\infty}=p(u,v)\\] 15.1.1 Distribuciones marginales 15.1.2 Variables aleatorias independientes 15.1.3 Distribuciones de probabilidad condicional 15.2 Distribución bidimensional continua "],["distribuciones-discreta-importantes.html", "Capítulo 16 Distribuciones discreta importantes 16.1 Variable aleatoria discreta binomial 16.2 Variable aleatoria discreta Poisson", " Capítulo 16 Distribuciones discreta importantes 16.1 Variable aleatoria discreta binomial 16.2 Variable aleatoria discreta Poisson "],["distribuciones-continuas-importantes.html", "Capítulo 17 Distribuciones continuas importantes 17.1 Variable aleatoria continua normal 17.2 Variable aleatoria continua gamma", " Capítulo 17 Distribuciones continuas importantes 17.1 Variable aleatoria continua normal 17.2 Variable aleatoria continua gamma "],["distribuciones-muestrales.html", "Capítulo 18 Distribuciones muestrales", " Capítulo 18 Distribuciones muestrales "],["estimación.html", "Capítulo 19 Estimación", " Capítulo 19 Estimación "],["prueba-de-hipótesis.html", "Capítulo 20 Prueba de hipótesis", " Capítulo 20 Prueba de hipótesis "],["sumatorias.html", "A Sumatorias A.1 eeeee", " A Sumatorias Una suma de números representados por \\(x_1, x_2, \\ldots, x_n\\) se simboliza en forma compacta mediante el simbolo \\(\\sum\\) (sigma) es decir la suma de los números anteriores se puede escribir del siguiente modo \\[x_1+x_2+\\dots+x_n=\\sum_{i=1}^nx_i.\\] Algunas propiedades son \\(k\\sum_{i=1}^nx_i=\\sum_{i=1}^nkx_i\\) \\(\\sum_{i=1}^n\\left(x_i+y_i\\right)=\\sum_{i=1}^nx_i+\\sum_{i=1}^ny_i\\) \\(\\sum_{i=1}^nx_i\\) \\[\\int_1^3=\\lim_{n\\to \\infty}\\sum_{i=0}^{n}f^i(x)\\] citado por (Xie 2015) Variable estadística variable estadística ## ee A.1 eeeee Referencias "],["matrices.html", "B Matrices B.1 Algebra de matrices", " B Matrices Una matriz es un arreglo de números distribuidos en filas y columnas por ejemplo la siguiente matriz \\[A=\\begin{pmatrix} a_{11}&amp;a_{12}&amp;\\ldots&amp;a_{1n}\\\\ a_{21}&amp;a_{22}&amp;\\ldots&amp;a_{2n}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots \\\\ a_{11}&amp;a_{11}&amp;\\ldots&amp;a_{nm} \\end{pmatrix}_{n\\times n}\\] de orden \\(n\\times m\\) tiene entradas \\(a_{ij}\\) donde el primer subindice indica la fila y el segundo la columna; es usual representar por simplicidad una matriz por \\(A=[a_{ij}]_{n\\times m}\\). Si en el orden \\(n=m\\) entonces la matriz recibe el nombre de matriz cuadrada la suma de los elementos de la diagonal de una matriz cuadrada \\(\\sum_{i=1}^na_{ii}\\) se llama traza. Si todas las \\(a_{ij}\\) son cero entonces la matriz \\(A=0\\) recibe el nombre matriz nula. Dos matrices son iguales si tienen el mismo orden y cada una de las entradas respectivas son iguales es decir \\(A=[a_{ij}]_{n\\times m}\\) y \\(B=[b_{ij}]_{n\\times m}\\) son iguales si \\(a_{ij}=b_{ij}\\), \\(i=1,2,\\ldots n\\) y \\(j=1,2,\\ldots m\\) B.1 Algebra de matrices Sean las matrices \\(A=[a_{ij}]_{n\\times m}\\) y \\(B=[b_{ij}]_{p\\times q}\\) entonces la suma y producto de matrices se definen Sea \\(k\\) un escalar entonces se verifica que \\(kA=[ka_{ij}]\\), \\(i=1,2,\\ldots n\\) y \\(j=1,2,\\ldots m\\) es decir el escalar \\(k\\) multiplica a cada una de las entradas de la matriz. La suma o diferencia es posible si \\(n=p\\) y \\(m=q\\) es decir los ordenes de \\(A\\) y \\(B\\) son iguales, entonces la suma o diferencia resulta \\(A\\pm B=[a_{ij}+b_{ij}]_{n\\times m}\\), \\(i=1,2,\\ldots n\\) y \\(j=1,2,\\ldots m\\) El producto es posible si \\(m=p\\) es decir el número columnas de la primera matriz es igual al número de filas de la segunda matriz, el orden de la matriz resultante es \\(n\\times q\\) además \\[\\begin{align*} A\\cdot B&amp;=\\left[\\sum_{k=1}^pa_{ik}b_{kj}\\right]_{n\\times q}\\\\ &amp;=\\begin{pmatrix} \\sum_{k=1}^ma_{1k}b_{k1}&amp;\\sum_{k=1}^ma_{1k}b_{k2}&amp;\\ldots&amp;\\sum_{k=1}^ma_{1k}b_{kq}\\\\ \\sum_{k=1}^ma_{2k}b_{k1}&amp;\\sum_{k=1}^ma_{2k}b_{k2}&amp;\\ldots&amp;\\sum_{k=1}^ma_{2k}b_{kq}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots \\\\ \\sum_{k=1}^ma_{nk}b_{k1}&amp;\\sum_{k=1}^ma_{nk}b_{k2}&amp;\\ldots&amp;\\sum_{k=1}^ma_{nk}b_{kq}\\\\ \\end{pmatrix}_{n\\times q} \\end{align*}\\] donde \\(i=1,2,\\ldots n\\) y \\(j=1,2,\\ldots m\\) Ejemplo B.1 Sean \\(\\begin{pmatrix} 3&amp;-1&amp;2\\\\ 2&amp;-1&amp;2\\\\ 1&amp;-1&amp;0\\\\ 5&amp;0&amp;0\\\\ \\end{pmatrix}_{4\\times 3}\\) y \\(\\begin{pmatrix} 0&amp;-1&amp;2&amp;2&amp;0\\\\ 1&amp;-1&amp;-2&amp;1&amp;1\\\\ 3&amp;-1&amp;-3&amp;5&amp;2\\\\ \\end{pmatrix}_{3\\times 5}\\) entonces \\(A\\cdot B=\\begin{pmatrix} 5&amp;-4&amp;2&amp;15&amp;3\\\\ 5&amp;-3&amp;0&amp;13&amp;3\\\\ -1&amp;0&amp;4&amp;1&amp;-1\\\\ 0&amp;-5&amp;10&amp;10&amp;0\\\\ \\end{pmatrix}_{4\\times 5}\\) En caso de ser posible la multiplicación entre \\(A\\), \\(B\\) y \\(C\\) entonces se verfican las siguientes propiedades \\(A(B+C)=AB+AC\\) \\((A+B)C\\) \\(A(BC)=(AB)C\\) xw = &#39;Es decir los elementos son demagogos y déspotas&#39; x1 = &#39;Es decir los elementos son demagogos y déspotas&#39; \\[ \\frac{\\sin x}{x^3} = 0.3794281 \\] \\[ \\Phi_{\\mu , \\sigma ^{2}}(x)=\\frac {1}{\\sigma {\\sqrt {2\\pi }}}e^{-{\\frac {(u-\\mu )^{2}}{2\\sigma ^{2}}}}du \\] * \\[\\frac{1}{20\\sqrt{2\\pi }}\\int_{-\\infty }^{ 300}e^{- \\frac{1}{2}\\left(\\frac{z-200}{20}\\right)^2}dz=0.9999997\\] * 0.9500042 also Es decir los elementos son demagogos y déspotas * Es decir los elementos son demagogos y déspotas Tabla B.1 Tabla B.1: Caption Option N w Observation Description Es decir los elementos son demagogos y déspotas Es decir los elementos son demagogos y déspotas 1 w Es decir los elementos son demagogos y déspotas Es decir los elementos son demagogos y déspotas Es decir los elementos son demagogos y déspotas Engine 2 w Es decir los elementos son demagogos y déspotas \\(\\sum^{n}_{i=1}{f_i}\\) Engine to be used for processing templates. Handlebars is the default. Es decir los elementos son demagogos y déspotas 3 w \\(\\sum^{n}_{i=1}{f_i}\\) extension to be used for dest files. variable aleatoria Variable aleatoria entonces 2.7182818 0.9750021 0.7881446 2561 The value of x in the Python session is Es decir los elementos son demagogos y déspotas . It is not the same x as the one in R. Figura B.1: Regresión lineal ## (Intercept) ## 12917.13 Sea la Tabla B.2 Figures and tables with captions will be placed in figure and table environments, respectively. Tabla B.2: Figures and tables with captions will be placed in figure \\(Y_i\\) \\(f_i\\) \\(F_i\\) \\(F_i^*\\) \\(h_i\\) \\(H_i\\) \\(H_i^*\\) \\(h_i\\%\\) \\(H_i\\%\\) \\(H_i^*\\%\\) ESTJ 1 1 75 0.01 0.01 1.00 1.33 1.33 100.00 ESTJ 2 3 150 0.03 0.04 2.00 2.67 4.00 200.00 ESTP 3 6 150 0.04 0.08 2.00 4.00 8.00 200.00 ESFJ 4 10 150 0.05 0.13 2.00 5.33 13.33 200.00 ESFP 6 16 150 0.08 0.21 2.00 8.00 21.33 200.00 ISTJ 6 22 155 0.08 0.29 2.07 8.00 29.33 206.67 ISTP 7 29 157 0.09 0.39 2.09 9.33 38.67 209.33 ISFJ 8 37 158 0.11 0.49 2.11 10.67 49.33 210.67 ISFP 9 46 166 0.12 0.61 2.21 12.00 61.33 221.33 ENTJ 10 56 166 0.13 0.75 2.21 13.33 74.67 221.33 ENTP 6 62 166 0.08 0.83 2.21 8.00 82.67 221.33 ENFJ 5 67 166 0.07 0.89 2.21 6.67 89.33 221.33 ENFP 3 70 166 0.04 0.93 2.21 4.00 93.33 221.33 INTJ 2 72 167 0.03 0.96 2.23 2.67 96.00 222.67 INTP 1 73 169 0.01 0.97 2.25 1.33 97.33 225.33 INFJ 1 74 172 0.01 0.99 2.29 1.33 98.67 229.33 INFP 1 75 176 0.01 1.00 2.35 1.33 100.00 234.67 "],["referencias.html", "Referencias", " Referencias "]]
